#!/usr/bin/env python3
"""
CycleGAN v7.0 Enhanced Web æ‡‰ç”¨
ä½¿ç”¨ä¸‰ç´šé›¢æ•£éœ§åº¦åˆ†ç´šçš„ v7 å¢å¼·ç‰ˆæ¨¡å‹
"""

import os
import io
import torch
import torch.nn as nn
import torch.nn.functional as F
import numpy as np
from PIL import Image
import torchvision.transforms as transforms
from flask import Flask, request, jsonify, render_template_string
import base64
import glob

# è§£æ±º spectral norm å•é¡Œ
def spectral_norm(module, name='weight', power_iterations=1):
    try:
        return torch.nn.utils.spectral_norm(module, name=name, n_power_iterations=power_iterations)
    except:
        return module

class SelfAttention(nn.Module):
    """è‡ªæ³¨æ„åŠ›æ©Ÿåˆ¶ - v7 ç‰ˆæœ¬"""
    def __init__(self, in_dim, activation=F.relu, with_attn=False):
        super(SelfAttention, self).__init__()
        self.chanel_in = in_dim
        self.activation = activation
        self.with_attn = with_attn
        
        if self.with_attn:
            self.query_conv = nn.Conv2d(in_channels=in_dim, out_channels=in_dim//8, kernel_size=1)
            self.key_conv = nn.Conv2d(in_channels=in_dim, out_channels=in_dim//8, kernel_size=1)
            self.value_conv = nn.Conv2d(in_channels=in_dim, out_channels=in_dim, kernel_size=1)
            self.gamma = nn.Parameter(torch.zeros(1))
    
    def forward(self, x):
        if not self.with_attn:
            return x
            
        batch_size, C, height, width = x.size()
        proj_query = self.query_conv(x).view(batch_size, -1, width*height).permute(0, 2, 1)
        proj_key = self.key_conv(x).view(batch_size, -1, width*height)
        
        energy = torch.bmm(proj_query, proj_key)
        attention = F.softmax(energy, dim=-1)
        
        proj_value = self.value_conv(x).view(batch_size, -1, width*height)
        out = torch.bmm(proj_value, attention.permute(0, 2, 1))
        out = out.view(batch_size, C, height, width)
        
        out = self.gamma * out + x
        return out

class ImprovedUpsample(nn.Module):
    """æ”¹é€²çš„ä¸Šæ¡æ¨£æ¨¡çµ„ - v7 ç‰ˆæœ¬"""
    def __init__(self, in_channels, out_channels, kernel_size=3):
        super(ImprovedUpsample, self).__init__()
        self.upsample = nn.Upsample(scale_factor=2, mode='nearest')
        self.conv = nn.Conv2d(in_channels, out_channels, kernel_size, padding=kernel_size//2)
        self.activation = nn.ReLU(inplace=True)
        
    def forward(self, x):
        x = self.upsample(x)
        x = self.conv(x)
        x = self.activation(x)
        return x

class ResidualBlock(nn.Module):
    """æ®˜å·®å¡Š - v7 ç‰ˆæœ¬"""
    def __init__(self, channels, use_dropout=False):
        super(ResidualBlock, self).__init__()
        self.conv_block = nn.Sequential(
            nn.ReflectionPad2d(1),
            spectral_norm(nn.Conv2d(channels, channels, 3)),
            nn.InstanceNorm2d(channels),
            nn.ReLU(inplace=True),
            nn.Dropout(0.5) if use_dropout else nn.Identity(),
            nn.ReflectionPad2d(1),
            spectral_norm(nn.Conv2d(channels, channels, 3)),
            nn.InstanceNorm2d(channels)
        )

    def forward(self, x):
        return x + self.conv_block(x)

class V7Generator(nn.Module):
    """CycleGAN v7 Enhanced ç”Ÿæˆå™¨"""
    def __init__(self, input_channels=3, output_channels=3, n_residual_blocks=9, use_self_attention=False):
        super(V7Generator, self).__init__()
        
        # ç·¨ç¢¼å™¨
        self.encoder = nn.Sequential(
            nn.ReflectionPad2d(3),
            spectral_norm(nn.Conv2d(input_channels, 64, 7)),
            nn.InstanceNorm2d(64),
            nn.ReLU(inplace=True),
            
            spectral_norm(nn.Conv2d(64, 128, 3, stride=2, padding=1)),
            nn.InstanceNorm2d(128),
            nn.ReLU(inplace=True),
            
            spectral_norm(nn.Conv2d(128, 256, 3, stride=2, padding=1)),
            nn.InstanceNorm2d(256),
            nn.ReLU(inplace=True)
        )
        
        # æ®˜å·®å¡Š
        residual_blocks = []
        for _ in range(n_residual_blocks):
            residual_blocks.append(ResidualBlock(256))
        self.residual_blocks = nn.Sequential(*residual_blocks)
        
        # è‡ªæ³¨æ„åŠ›ï¼ˆå¯é¸ï¼‰
        self.use_self_attention = use_self_attention
        if use_self_attention:
            self.self_attention = SelfAttention(256, with_attn=True)
        else:
            self.self_attention = SelfAttention(256, with_attn=False)
        
        # è§£ç¢¼å™¨ - ä½¿ç”¨æ”¹é€²çš„ä¸Šæ¡æ¨£
        self.decoder = nn.Sequential(
            ImprovedUpsample(256, 128),
            nn.InstanceNorm2d(128),
            
            ImprovedUpsample(128, 64),
            nn.InstanceNorm2d(64),
            
            nn.ReflectionPad2d(3),
            nn.Conv2d(64, output_channels, 7),
            nn.Tanh()
        )

    def forward(self, x):
        encoded = self.encoder(x)
        residual = self.residual_blocks(encoded)
        attended = self.self_attention(residual)
        output = self.decoder(attended)
        return output

# å…¨åŸŸè®Šæ•¸
app = Flask(__name__)
app.config['MAX_CONTENT_LENGTH'] = 16 * 1024 * 1024  # 16MB

device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')
generator = None
current_model_path = None

def get_all_v7_models():
    """ç²å–æ‰€æœ‰å¯ç”¨çš„ v7 æ¨¡å‹"""
    v7_models = glob.glob('checkpoints/cyclegan_v7_enhanced_no_attn_epoch_*.pth')
    if not v7_models:
        v7_models = glob.glob('checkpoints/cyclegan_v7_enhanced_epoch_*.pth')
    
    if not v7_models:
        return []
    
    # æŒ‰ epoch æ•¸å­—æ’åº
    v7_models.sort(key=lambda x: int(x.split('_epoch_')[1].split('.')[0]))
    return v7_models

def find_latest_v7_model():
    """å°‹æ‰¾æœ€æ–°çš„ v7 æ¨¡å‹"""
    v7_models = get_all_v7_models()
    
    if not v7_models:
        print("âŒ æ‰¾ä¸åˆ°ä»»ä½• v7 æ¨¡å‹æª”æ¡ˆ")
        return None
    
    latest_model = v7_models[-1]
    print(f"ğŸ” æ‰¾åˆ° v7 æ¨¡å‹: {latest_model}")
    return latest_model

def load_v7_model(model_path=None):
    """è¼‰å…¥ v7 æ¨¡å‹"""
    global generator, current_model_path
    
    try:
        print("ğŸ”„ è¼‰å…¥ CycleGAN v7 Enhanced æ¨¡å‹...")
        
        # å¦‚æœæ²’æŒ‡å®šæ¨¡å‹ï¼Œä½¿ç”¨æœ€æ–°çš„
        if model_path is None:
            model_path = find_latest_v7_model()
        
        if model_path is None:
            return False, "æ‰¾ä¸åˆ°ä»»ä½• v7 æ¨¡å‹æª”æ¡ˆ"
        
        # åˆå§‹åŒ–ç”Ÿæˆå™¨
        generator = V7Generator(use_self_attention=False).to(device)
        
        # è¼‰å…¥æ¬Šé‡
        checkpoint = torch.load(model_path, map_location=device)
        
        # è¼‰å…¥ generator_AB (æœ‰éœ§â†’æ¸…æ™°)
        if 'generator_AB' in checkpoint:
            generator.load_state_dict(checkpoint['generator_AB'])
            current_model_path = model_path
            print(f"âœ… æˆåŠŸè¼‰å…¥ v7 æ¨¡å‹: {model_path}")
        else:
            print("âŒ æ¨¡å‹æª”æ¡ˆä¸­æ²’æœ‰ generator_AB")
            return False, "æ¨¡å‹æª”æ¡ˆä¸­æ²’æœ‰ generator_AB"
        
        generator.eval()
        return True, model_path
        
    except Exception as e:
        print(f"âŒ v7 æ¨¡å‹è¼‰å…¥å¤±æ•—: {e}")
        return False, str(e)

def process_image_v7(image_pil):
    """ä½¿ç”¨ v7 æ¨¡å‹è™•ç†åœ–åƒ"""
    global generator
    
    try:
        # ä¿æŒæ¯”ä¾‹çš„åœ–åƒè½‰æ›
        original_size = image_pil.size
        
        # è¨ˆç®—é©ç•¶çš„è™•ç†å°ºå¯¸ï¼ˆé©é…æ¨¡å‹ï¼‰
        def get_processing_size(w, h, target_size=512):
            scale = target_size / max(w, h)
            new_w = int(w * scale)
            new_h = int(h * scale)
            
            # ç¢ºä¿èƒ½è¢«32æ•´é™¤
            new_w = (new_w // 32) * 32
            new_h = (new_h // 32) * 32
            
            # æœ€å°å°ºå¯¸ä¿è­‰
            new_w = max(new_w, 256)
            new_h = max(new_h, 256)
            
            return new_w, new_h
        
        proc_w, proc_h = get_processing_size(original_size[0], original_size[1])
        
        # åœ–åƒè½‰æ›
        transform = transforms.Compose([
            transforms.Resize((proc_h, proc_w)),
            transforms.ToTensor(),
            transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))
        ])
        
        # è™•ç†åœ–åƒ
        input_tensor = transform(image_pil).unsqueeze(0).to(device)
        
        with torch.no_grad():
            output_tensor = generator(input_tensor)
        
        # è½‰æ›å› PIL
        output_numpy = output_tensor.squeeze().cpu().numpy()
        output_numpy = (output_numpy + 1.0) / 2.0
        output_numpy = np.transpose(output_numpy, (1, 2, 0))
        output_numpy = np.clip(output_numpy * 255, 0, 255).astype(np.uint8)
        
        result_image = Image.fromarray(output_numpy)
        
        # èª¿æ•´å›åŸå§‹å°ºå¯¸
        if result_image.size != original_size:
            result_image = result_image.resize(original_size, Image.Resampling.LANCZOS)
        
        return result_image
        
    except Exception as e:
        print(f"âŒ v7 åœ–åƒè™•ç†å¤±æ•—: {e}")
        return None

@app.route('/')
def index():
    return render_template_string('''
<!DOCTYPE html>
<html lang="zh-TW">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>CycleGAN v7.0 Enhanced å»éœ§ç³»çµ±</title>
    <style>
        body { 
            font-family: Arial, sans-serif; 
            max-width: 1200px; 
            margin: 0 auto; 
            padding: 20px; 
            background: linear-gradient(135deg, #667eea 0%, #764ba2 100%);
            color: #333;
        }
        .container { background: white; border-radius: 15px; padding: 30px; box-shadow: 0 10px 30px rgba(0,0,0,0.3); }
        .header { text-align: center; margin-bottom: 30px; }
        .header h1 { color: #4a5568; margin: 0; font-size: 2.5em; }
        .header p { color: #718096; font-size: 1.1em; margin: 10px 0; }
        
        .upload-section { 
            background: #f7fafc; 
            padding: 30px; 
            border-radius: 10px; 
            margin-bottom: 20px; 
            border: 2px dashed #cbd5e0;
            transition: all 0.3s ease;
        }
        .upload-section:hover { border-color: #4299e1; background: #ebf8ff; }
        
        .upload-area { 
            text-align: center; 
            cursor: pointer; 
            padding: 40px;
            border-radius: 8px;
        }
        
        .btn { 
            background: linear-gradient(135deg, #4299e1, #3182ce); 
            color: white; 
            padding: 12px 24px; 
            border: none; 
            border-radius: 25px; 
            cursor: pointer; 
            font-size: 16px; 
            margin: 5px;
            transition: all 0.3s ease;
            box-shadow: 0 4px 15px rgba(66, 153, 225, 0.3);
        }
        .btn:hover { 
            background: linear-gradient(135deg, #3182ce, #2c5282); 
            transform: translateY(-2px);
            box-shadow: 0 6px 20px rgba(66, 153, 225, 0.4);
        }
        .btn:disabled { 
            background: #a0aec0; 
            cursor: not-allowed; 
            transform: none;
            box-shadow: none;
        }
        
        .results { 
            background: white; 
            padding: 30px; 
            border-radius: 10px; 
            box-shadow: 0 4px 15px rgba(0,0,0,0.1); 
            display: none; 
            margin-top: 20px;
        }
        
        .image-comparison { 
            display: grid; 
            grid-template-columns: 1fr 1fr; 
            gap: 20px; 
            margin-top: 20px; 
        }
        
        .image-container { 
            text-align: center; 
            background: #f8f9fa;
            padding: 20px;
            border-radius: 10px;
        }
        .image-container h4 { 
            margin-top: 0; 
            color: #2d3748;
            font-size: 1.2em;
        }
        .image-container img { 
            max-width: 100%; 
            border-radius: 8px; 
            box-shadow: 0 4px 15px rgba(0,0,0,0.2);
            transition: transform 0.3s ease;
        }
        .image-container img:hover { transform: scale(1.05); }
        
        .loading { 
            text-align: center; 
            padding: 40px; 
            display: none; 
            background: white;
            border-radius: 10px;
            margin: 20px 0;
        }
        
        .spinner { 
            border: 4px solid #f3f3f3; 
            border-top: 4px solid #4299e1; 
            border-radius: 50%; 
            width: 50px; 
            height: 50px; 
            animation: spin 1s linear infinite; 
            margin: 0 auto 20px; 
        }
        @keyframes spin { 0% { transform: rotate(0deg); } 100% { transform: rotate(360deg); } }
        
        .status { 
            padding: 15px; 
            margin: 15px 0; 
            border-radius: 8px; 
            text-align: center; 
            font-weight: bold;
        }
        .status.success { 
            background: #c6f6d5; 
            color: #22543d; 
            border: 1px solid #9ae6b4; 
        }
        .status.error { 
            background: #fed7d7; 
            color: #742a2a; 
            border: 1px solid #fc8181; 
        }
        
        .model-info {
            background: #edf2f7;
            padding: 20px;
            border-radius: 10px;
            margin-bottom: 20px;
            text-align: center;
        }
        
        .model-info h3 {
            color: #2d3748;
            margin: 0 0 10px 0;
        }
        
        .feature-list {
            color: #4a5568;
            font-size: 0.9em;
            line-height: 1.6;
        }
        
        .model-selector {
            background: #f8f9fa;
            padding: 20px;
            border-radius: 10px;
            margin-bottom: 20px;
            text-align: center;
        }
        
        .model-selector select {
            padding: 10px 15px;
            border: 2px solid #e2e8f0;
            border-radius: 8px;
            background: white;
            font-size: 14px;
            color: #2d3748;
            min-width: 200px;
            margin-right: 10px;
        }
        
        .model-selector select:focus {
            outline: none;
            border-color: #4299e1;
        }
        
        .btn-switch {
            background: linear-gradient(135deg, #38b2ac, #319795);
            color: white;
            padding: 10px 20px;
            border: none;
            border-radius: 25px;
            cursor: pointer;
            font-size: 14px;
            margin-left: 10px;
            transition: all 0.3s ease;
        }
        
        .btn-switch:hover {
            background: linear-gradient(135deg, #319795, #2c7a7b);
            transform: translateY(-1px);
        }
        
        @media (max-width: 768px) { 
            .image-comparison { grid-template-columns: 1fr; }
            .container { padding: 20px; }
            .header h1 { font-size: 2em; }
        }
    </style>
</head>
<body>
    <div class="container">
        <div class="header">
            <h1>ğŸŒŸ CycleGAN v7.0 Enhanced</h1>
            <p>ä¸‰ç´šé›¢æ•£éœ§åº¦åˆ†ç´š â€¢ æ™ºèƒ½å»éœ§ç³»çµ±</p>
        </div>
        
        <div class="model-selector">
            <h3>ğŸ”§ æ¨¡å‹é¸æ“‡</h3>
            <select id="modelSelect">
                <option value="">è¼‰å…¥å¯ç”¨æ¨¡å‹...</option>
            </select>
            <button class="btn-switch" onclick="switchModel()">åˆ‡æ›æ¨¡å‹</button>
            <p id="currentModel" style="margin-top: 10px; font-size: 0.9em; color: #666;">
                ç•¶å‰æ¨¡å‹: è¼‰å…¥ä¸­...
            </p>
        </div>
        
        <div class="model-info">
            <h3>ğŸš€ v7 å¢å¼·ç‰ˆç‰¹è‰²</h3>
            <div class="feature-list">
                âœ¨ é€£çºŒæ¬Šé‡æ¨¡å¼ (å¹³æ»‘éœ§åº¦èª¿æ•´)<br>
                ï¿½ å¼·éœ§ Gamma æ ¡æ­£ (1.1~1.3)<br>
                ğŸ’¡ ç”Ÿæˆå™¨äº®åº¦å„ªåŒ– (é˜²åæš—)<br>
                ğŸ›¡ï¸ é‚Šç·£ç´‹ç†è£œå„Ÿæ©Ÿåˆ¶<br>
                ğŸ”§ æ”¹é€²çš„ä¸Šæ¡æ¨£é¿å…æ£‹ç›¤æ•ˆæ‡‰<br>
                ğŸ“Š å¤šå°ºåº¦è¨“ç·´æ•¸æ“šé›†
            </div>
        </div>
        
        <div class="upload-section">
            <h3>ğŸ“ ä¸Šå‚³æœ‰éœ§åœ–åƒ</h3>
            <div class="upload-area" onclick="document.getElementById('fileInput').click()">
                <p style="font-size: 1.2em; margin: 0;">ğŸ“· é»æ“Šæ­¤è™•é¸æ“‡åœ–åƒæ–‡ä»¶</p>
                <p style="color: #666; font-size: 14px; margin: 10px 0 0 0;">æ”¯æŒ JPG, PNG ç­‰æ ¼å¼ï¼Œæœ€å¤§ 16MB</p>
            </div>
            <input type="file" id="fileInput" accept="image/*" style="display: none;">
            <br><br>
            <button class="btn" id="processBtn" onclick="processImage()" disabled>ğŸš€ é–‹å§‹ v7 å»éœ§è™•ç†</button>
        </div>
        
        <div class="loading" id="loading">
            <div class="spinner"></div>
            <p id="loadingText">æ­£åœ¨ä½¿ç”¨ v7 Enhanced æ¨¡å‹è™•ç†åœ–åƒ...</p>
        </div>
        
        <div class="results" id="results">
            <h3>ğŸ“Š v7 Enhanced å»éœ§çµæœ</h3>
            <div class="image-comparison">
                <div class="image-container">
                    <h4>ğŸŒ«ï¸ åŸå§‹æœ‰éœ§åœ–åƒ</h4>
                    <img id="originalImg" alt="åŸå§‹åœ–åƒ">
                </div>
                <div class="image-container">
                    <h4>âœ¨ v7 å»éœ§çµæœ</h4>
                    <img id="resultImg" alt="v7 å»éœ§çµæœ">
                </div>
            </div>
        </div>
        
        <div id="status" class="status" style="display: none;"></div>
    </div>

    <script>
        let selectedFile = null;
        
        // é é¢è¼‰å…¥æ™‚ç²å–å¯ç”¨æ¨¡å‹
        document.addEventListener('DOMContentLoaded', function() {
            loadAvailableModels();
        });
        
        function loadAvailableModels() {
            fetch('/get_models')
            .then(response => response.json())
            .then(data => {
                if (data.success) {
                    const select = document.getElementById('modelSelect');
                    select.innerHTML = '';
                    
                    data.models.forEach(model => {
                        const option = document.createElement('option');
                        option.value = model.path;
                        option.textContent = model.name;
                        if (model.is_current) {
                            option.selected = true;
                        }
                        select.appendChild(option);
                    });
                    
                    // æ›´æ–°ç•¶å‰æ¨¡å‹é¡¯ç¤º
                    if (data.current_model) {
                        const currentEpoch = data.current_model.split('_epoch_')[1].split('.')[0];
                        document.getElementById('currentModel').textContent = 
                            `ç•¶å‰æ¨¡å‹: v7 Enhanced Epoch ${currentEpoch}`;
                    }
                } else {
                    showStatus('è¼‰å…¥æ¨¡å‹åˆ—è¡¨å¤±æ•—', 'error');
                }
            })
            .catch(error => {
                showStatus('è¼‰å…¥æ¨¡å‹åˆ—è¡¨æ™‚ç™¼ç”ŸéŒ¯èª¤', 'error');
                console.error('Error:', error);
            });
        }
        
        function switchModel() {
            const select = document.getElementById('modelSelect');
            const selectedModel = select.value;
            
            if (!selectedModel) {
                showStatus('è«‹é¸æ“‡ä¸€å€‹æ¨¡å‹', 'error');
                return;
            }
            
            showStatus('æ­£åœ¨åˆ‡æ›æ¨¡å‹...', 'success');
            
            fetch('/switch_model', {
                method: 'POST',
                headers: {
                    'Content-Type': 'application/json',
                },
                body: JSON.stringify({
                    model_path: selectedModel
                })
            })
            .then(response => response.json())
            .then(data => {
                if (data.success) {
                    const currentEpoch = data.current_model.split('_epoch_')[1].split('.')[0];
                    document.getElementById('currentModel').textContent = 
                        `ç•¶å‰æ¨¡å‹: v7 Enhanced Epoch ${currentEpoch}`;
                    showStatus('æ¨¡å‹åˆ‡æ›æˆåŠŸï¼', 'success');
                } else {
                    showStatus(`æ¨¡å‹åˆ‡æ›å¤±æ•—: ${data.error}`, 'error');
                }
            })
            .catch(error => {
                showStatus('åˆ‡æ›æ¨¡å‹æ™‚ç™¼ç”ŸéŒ¯èª¤', 'error');
                console.error('Error:', error);
            });
        }
        
        document.getElementById('fileInput').addEventListener('change', function(event) {
            const file = event.target.files[0];
            if (file) {
                selectedFile = file;
                document.getElementById('processBtn').disabled = false;
                document.getElementById('results').style.display = 'none';
                showStatus(`å·²é¸æ“‡æ–‡ä»¶: ${file.name}`, 'success');
            }
        });
        
        function processImage() {
            if (!selectedFile) {
                showStatus('è«‹å…ˆé¸æ“‡åœ–åƒæ–‡ä»¶', 'error');
                return;
            }
            
            const formData = new FormData();
            formData.append('image', selectedFile);
            
            document.getElementById('loading').style.display = 'block';
            document.getElementById('processBtn').disabled = true;
            
            fetch('/process_v7', {
                method: 'POST',
                body: formData
            })
            .then(response => response.json())
            .then(data => {
                document.getElementById('loading').style.display = 'none';
                document.getElementById('processBtn').disabled = false;
                
                if (data.success) {
                    document.getElementById('originalImg').src = data.original_image;
                    document.getElementById('resultImg').src = data.result_image;
                    document.getElementById('results').style.display = 'block';
                    showStatus('v7 Enhanced å»éœ§è™•ç†å®Œæˆï¼', 'success');
                } else {
                    showStatus(`v7 è™•ç†å¤±æ•—: ${data.error}`, 'error');
                }
            })
            .catch(error => {
                document.getElementById('loading').style.display = 'none';
                document.getElementById('processBtn').disabled = false;
                showStatus('v7 è™•ç†æ™‚ç™¼ç”ŸéŒ¯èª¤', 'error');
                console.error('Error:', error);
            });
        }
        
        function showStatus(message, type) {
            const status = document.getElementById('status');
            status.className = `status ${type}`;
            status.textContent = message;
            status.style.display = 'block';
            setTimeout(() => {
                status.style.display = 'none';
            }, 4000);
        }
    </script>
</body>
</html>
    ''')

@app.route('/get_models', methods=['GET'])
def get_available_models():
    """ç²å–æ‰€æœ‰å¯ç”¨çš„ v7 æ¨¡å‹"""
    try:
        v7_models = get_all_v7_models()
        models_info = []
        
        for model_path in v7_models:
            # æå– epoch æ•¸å­—
            epoch = int(model_path.split('_epoch_')[1].split('.')[0])
            model_name = f"v7 Enhanced Epoch {epoch}"
            
            models_info.append({
                'path': model_path,
                'name': model_name,
                'epoch': epoch,
                'is_current': model_path == current_model_path
            })
        
        return jsonify({
            'success': True,
            'models': models_info,
            'current_model': current_model_path
        })
        
    except Exception as e:
        return jsonify({'success': False, 'error': str(e)})

@app.route('/switch_model', methods=['POST'])
def switch_model():
    """åˆ‡æ› v7 æ¨¡å‹"""
    try:
        data = request.get_json()
        model_path = data.get('model_path')
        
        if not model_path:
            return jsonify({'success': False, 'error': 'è«‹æŒ‡å®šæ¨¡å‹è·¯å¾‘'})
        
        success, message = load_v7_model(model_path)
        
        if success:
            return jsonify({
                'success': True,
                'message': f'æˆåŠŸåˆ‡æ›åˆ°æ¨¡å‹: {model_path}',
                'current_model': current_model_path
            })
        else:
            return jsonify({'success': False, 'error': message})
            
    except Exception as e:
        return jsonify({'success': False, 'error': str(e)})

@app.route('/process_v7', methods=['POST'])
def process_v7_image():
    """ä½¿ç”¨ v7 æ¨¡å‹è™•ç†ä¸Šå‚³çš„åœ–åƒ"""
    try:
        if 'image' not in request.files:
            return jsonify({'success': False, 'error': 'æ²’æœ‰ä¸Šå‚³åœ–åƒ'}), 400
        
        file = request.files['image']
        if file.filename == '':
            return jsonify({'success': False, 'error': 'æ²’æœ‰é¸æ“‡æ–‡ä»¶'}), 400
        
        print(f"ğŸ¯ ä½¿ç”¨ v7 Enhanced è™•ç†åœ–åƒ: {file.filename}")
        
        # è¼‰å…¥åœ–åƒ
        image_pil = Image.open(io.BytesIO(file.read())).convert('RGB')
        
        # ä½¿ç”¨ v7 æ¨¡å‹è™•ç†
        result_image = process_image_v7(image_pil)
        
        if result_image is None:
            return jsonify({'success': False, 'error': 'v7 åœ–åƒè™•ç†å¤±æ•—'}), 500
        
        # è½‰ç‚ºbase64
        def pil_to_base64(img):
            buffer = io.BytesIO()
            img.save(buffer, format='PNG')
            return f"data:image/png;base64,{base64.b64encode(buffer.getvalue()).decode()}"
        
        return jsonify({
            'success': True,
            'original_image': pil_to_base64(image_pil),
            'result_image': pil_to_base64(result_image),
            'model_version': 'v7.0 Enhanced'
        })
        
    except Exception as e:
        print(f"âŒ v7 è™•ç†éŒ¯èª¤: {e}")
        return jsonify({'success': False, 'error': str(e)}), 500

if __name__ == '__main__':
    print("ğŸŒ è¼‰å…¥ CycleGAN v7.0 Enhanced å»éœ§ç³»çµ±...")
    success, message = load_v7_model()
    if success:
        print(f"ğŸš€ å•Ÿå‹• v7 Enhanced å»éœ§æœå‹™ - {message}")
        app.run(host='0.0.0.0', port=5007, debug=True)
    else:
        print(f"âŒ v7 æ¨¡å‹è¼‰å…¥å¤±æ•—ï¼Œç„¡æ³•å•Ÿå‹•æœå‹™: {message}")
